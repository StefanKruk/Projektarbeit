\chapter{Theorie neuronaler Netze}
\label{chap:theorie}

\section{Die formalen Neuronen}
In diesen Abschnitten geht es um die mathematischen Grundlagen der zu
behandelnden Problemstellung. Hier können Definitionen und Sätze
auftauchen, wobei die Sätze teils bewiesen werden sollten (falls einfach
und für das weitere Verständnis wesentlich) oder ihre Beweise sauber
zitiert werden. Beispiele: \\
\begin{definition}[Formales Neuron]
Ein formales Neuron ist eine Funktion
$\kappa: \RR^n \to \RR^m$, die erzeugt wird durch die Verkettung 
einer sogenannten {\sl Transferfunktion} 
$\sigma: \RR \to \RR$ mit einer sogenannten
{\sl Aktivierungsfunktion} $A: \RR^n \to \RR$:
\begin{equation}
\begin{array}{rl}
\kappa: \ \ \ & \RR^n \to \RR^m \ , \\
        & \ \ \ \vec x \mapsto 
        \big( \sigma(A(\vec x)), \sigma(A(\vec x)), \ \ldots \ ,
                               \sigma(A(\vec x)) \big) \ . 
\end{array} 
\end{equation}			       
\end{definition}

\begin{theorem}[Dichtheitssatz für hyperbolische Aktivierung]
Es sei $f: \RR^n \to \RR$ stetig, $K \subset \RR^n$ kompakt
und $\sigma: \RR \to \RR$ eine stetige Sigmoidalfunktion.
Dann gibt es für alle $\epsilon > 0$ Parameter
\begin{equation}
\begin{array}{rl}
& q \in \NN, \\
& d_{kp} \in \RR, \ \ 1 \le k \le n , \ 1 \le p \le q , \\
& \rho_p \in \RR, \ \ \ 1 \le p \le q , \\
& g_p \in \RR, \ \ \ 1 \le p \le q , 
\end{array}\end{equation}
so dass für alle $\vec x \in K$ gilt
\begin{equation}
\left| f(\vec x ) - \sum_{p=1}^q g_p \sigma 
\left( \rho_p \prod\limits_{k=1}^n (x_k-d_{kp}) \right) \right| \ < \ \epsilon .
\end{equation}
Definiert man nun
\begin{equation}
\sigma_{\pi}(\vec x ) := \sigma(\prod_{k=1}^n x_k) \ ,
\end{equation}
so lässt sich dies auch kurz schreiben als
\begin{equation}
H_{\sigma}  :=	\overline{span} \; \left\{ \sigma_{\pi}(\rho ( \vec x - \vec d \, )) \; : \;
\vec d \in \RR^n, \; \rho \in \RR \right\}	=  C(\RR^n ) \ ,
\end{equation}
wobei $\overline{span}$ den Abschluss bezüglich der Topologie der
gleichmäßigen Konvergenz auf kompakten Mengen bezeichnet.
\end{theorem}
\noindent
\begin{proof}
Vergleiche die Originalarbeiten \cite{Lenze_Note_1994,Pinkus_TDI_1996} oder \cite[][S.\ 163ff]{Lenze_Einfuehrung_2003}.
\end{proof}
\\
\noindent
Auch Zeichnungen (vgl. \autoref{fig:neuron}) können sinnvoll sein und
eingebunden werden: 

\begin{figure}[htb]
%\centerline{\includegraphics[width=8cm]{feubild1}}
\caption[Reales Neuron]{\label{fig:neuron}Reales Neuron (Schematische Skizze)}
\end{figure}

\section{Die Topologie neuronaler Strukturen}

\section{Der Ausführ-Modus}

\section{Der Lern-Modus}
Um Algorithmen zu erläutern kann es sinnvoll sein Pseudocode zu verwenden. Ein Beispiel dafür ist der \autoref{pseu:berechne}. 
\begin{pseudocode} 
\caption{Berechne $y = x^n$}
\label{pseu:berechne}
\begin{algorithmic}[1]
    \Require $n \geq 0 \vee x \neq 0$
    \Ensure $y = x^n$
    \State $y \Leftarrow 1$
    \If{$n < 0$}
        \State $X \Leftarrow 1 / x$
        \State $N \Leftarrow -n$
    \Else
        \State $X \Leftarrow x$
        \State $N \Leftarrow n$
    \EndIf
    \While{$N \neq 0$}
        \If{$N$ ist gerade}
            \State $X \Leftarrow X \times X$
            \State $N \Leftarrow N / 2$
        \Else
            \State $y \Leftarrow y \times X$
            \State $N \Leftarrow N - 1$
        \EndIf
    \EndWhile
\end{algorithmic}
\end{pseudocode}